---
title: 给 Selenium 提提速
updated: 2018-10-24
---
### 前言
Selenium 是一个同步库，在使用 get() 方法或点击某元素进行页面跳转时，必须等到网页全部加载完成才能进行下一步操作。

自动化测试还好，如果使用 Selenium 进行爬虫就必须保证代理 IP 的速度，否则页面就一直在那转圈圈，所以说，使用 Selenium 爬虫真是煎熬啊。

用 Selenium 爬了一段时间后，终于无法忍受 Selenium 的运行速度了，所以就去翻 Selenium 的官方文档......此处省略一万个字。

我发现，通过修改 Chrome 的页面加载策略可以达到异步效果，正好 Selenium 提供了这一接口。

先看代码，然后再进行说明。
```python
import datetime

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
from selenium.common.exceptions import TimeoutException

desired_capabilities = DesiredCapabilities.CHROME
desired_capabilities['pageLoadStrategy'] = 'none'
driver = webdriver.Chrome(executable_path='driver/chromedriver', desired_capabilities=desired_capabilities)
timeout = WebDriverWait(driver, 30)

start_time = datetime.datetime.now()
try:
    driver.get('http://book.dangdang.com/')
    # 查找搜索框
    search_box = timeout.until(expected_conditions.element_to_be_clickable((By.ID, 'key_S')))
    # 查找搜索按钮
    search_button = timeout.until(expected_conditions.element_to_be_clickable((By.CLASS_NAME, 'button')))
    search_box.send_keys('python')
    # 点击搜索按钮后，页面会原地跳转
    search_button.click()
    # 查找书名
    search_result = timeout.until(expected_conditions.visibility_of_all_elements_located((By.CLASS_NAME, 'name')))
except TimeoutException:
    driver.quit()
    print('超时')
else:
    for book_name in search_result:
        print(book_name.text)
    driver.quit()
    end_time = datetime.datetime.now()
    print(str((end_time - start_time).seconds) + '秒')
```

### 补充说明
其实真正起到作用的仅仅只需3行半代码，下面来逐行解释。

首先导入 DesiredCapabilities 类。
```python
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
```

实例化该类，并指定浏览器类型为 CHROME
```python
desired_capabilities = DesiredCapabilities.CHROME
```

然后指定页面加载策略为 none。
```python
desired_capabilities['pageLoadStrategy'] = 'none'
```

最后一步就是需要把策略加到 webdriver 中。
```python
driver = webdriver.Chrome(executable_path='driver/chromedriver', desired_capabilities=desired_capabilities)
```

none 在这里的意思是当 html 下载完成之后，不等待解析完成，Selenium 会直接返回。

> **注意：**在极快的网络环境中对比同步和异步，效果不算太明显，所以这里就不贴运行结果了。